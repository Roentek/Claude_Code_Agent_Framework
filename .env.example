# API Keys and Environment Variables
# Copy this file to .env and fill in your values
# NEVER commit .env to version control

# === MCP Server Integrations ===
# These power the pre-configured MCP servers in .mcp.json
SUPABASE_API_PAT=                      # Supabase MCP access token
SUPABASE_PROJECT_URL=                  # Supabase project URL
SUPABASE_PROJECT_KEY=                  # Supabase project key
PINECONE_API_KEY=                      # Pinecone vector DB API key
APIFY_API_PAT=                         # Apify web scraping access token
TAVILY_API_KEY=                        # Tavily search API key
VAPI_SDK_KEY=                          # Vapi SDK key (for client use)
VAPI_API_TOKEN=                        # Vapi MCP server token
N8N_HOST_URL=                          # n8n instance URL (e.g., https://your-instance.n8n.cloud)
N8N_API_KEY=                           # n8n API key for MCP access
GOOGLE_USER_EMAIL=                     # Google email for single-user auth
GOOGLE_OAUTH_CLIENT_ID=                # Google Workspace MCP OAuth client ID
GOOGLE_OAUTH_CLIENT_SECRET=            # Google Workspace MCP OAuth client secret
OPENROUTER_API_KEY=                    # OpenRouter API key (no quotes required)

# === MCP Apps Server ===
MCP_SERVER_URL=http://localhost:3001/mcp  # Local HTTP MCP server for generative UI

# === CopilotKit / OpenRouter ===
# CopilotKit uses the OpenAI SDK internally. By setting OPENAI_BASE_URL to
# OpenRouter's endpoint, all LLM calls route through OpenRouter transparently.
OPENAI_API_KEY=                                                 # Your OpenRouter API key (same as OPENROUTER_API_KEY)
OPENAI_BASE_URL=https://openrouter.ai/api/v1

# === OpenRouter Models ===
# Model to use (see https://openrouter.ai/models)       
OPENROUTER_MODEL=openai/gpt-4o                                  # OpenAI GPT-4 Omni (default, balanced performance)
# OPENROUTER_MODEL=openai/gpt-4o-mini                           # OpenAI GPT-4 Omni Mini (faster, cheaper)
# OPENROUTER_MODEL=anthropic/claude-sonnet-4                    # Claude Sonnet 4 (excellent reasoning)
# OPENROUTER_MODEL=anthropic/claude-opus-4                      # Claude Opus 4 (most capable)
# OPENROUTER_MODEL=google/gemini-2.0-flash-thinking-exp:free    # Google Gemini 2.0 Flash (free tier)
# OPENROUTER_MODEL=meta-llama/llama-3.3-70b-instruct            # Llama 3.3 70B Instruct (open model, high performance)
# OPENROUTER_MODEL=meta-llama/llama-3.3-70b-chat                # Llama 3.3 70B Chat (open model, chat optimized)
# OPENROUTER_MODEL=deepseek/deepseek-chat                       # DeepSeek Chat (open model, good performance, cost effective)
